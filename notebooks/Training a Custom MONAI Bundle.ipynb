{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a Custom MONAI Bundle on NVIDIA DGX Cloud\n",
    "\n",
    "This comprehensive guide is designed to help you navigate the process of training a custom MONAI Bundle on the NVIDIA DGX Cloud, focusing on leveraging the powerful capabilities of DGX systems for medical imaging applications.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Dataset Creation](#Dataset-Creation)\n",
    "1. [Custom MONAI Bundle Creation](#Custom-Monai-Bundle-Creation)\n",
    "1. [Training on DGX Cloud](#Training-on-DGX-Cloud)\n",
    "1. [Monitoring and Downloading](#Monitoring-and-Download)\n",
    "1. [Conclusion](#Conclusion)\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Training a custom MONAI Bundle on the NVIDIA DGX Cloud represents a significant step in advancing medical imaging projects. This guide aims to facilitate your journey, ensuring you harness the full potential of DGX's high-performance computing for deep learning. We'll cover the steps from initializing your custom bundle to optimizing your training process on DGX Cloud.\n",
    "\n",
    "If you haven't already generated your key or if you're unsure about the process, follow our step-by-step for [Generating and Managing Your Credentials](./Generating%20and%20Managing%20Your%20Credentials.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "# API Endpoint and Credentials\n",
    "monai_cloud_api = \"<MONAI Cloud API URL>\"\n",
    "api_url = f\"{monai_cloud_api}/api/v1\"\n",
    "ngc_api_key = \"<NGC API Key>\"\n",
    "\n",
    "# NGC UID \n",
    "response = requests.get(f\"{api_url}/login/{ngc_api_key}\")\n",
    "uid = response.json()[\"user_id\"]\n",
    "token = response.json()[\"token\"]\n",
    "\n",
    "# Construct the URL and Headers\n",
    "base_url = f\"{api_url}/user/{uid}\"\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Cration\n",
    "\n",
    "### **1. Remote Object as Data Sources**\n",
    "\n",
    "MONAI Cloud platform supports a range of other cloud storage solutions, including Azure Blob Storage, Google Cloud Storage (GCP) and Amazon S3, providing you with the flexibility to choose the service that best fits your project's needs. Below is an example of Azure:\n",
    "\n",
    "**Steps:**\n",
    "1. Creating a Storage Account and Container\n",
    "   - **Storage Account**: Start by creating a new storage account in your Azure portal. This account will host your blob storage containers.\n",
    "   - **Container Creation**: Within your storage account, create a new container. This container will hold your datasets.\n",
    "\n",
    "2. Container URL\n",
    "   - Once the container is created, you will be provided with a unique URL that can be used to access it. This URL will be essential for accessing your data.\n",
    "\n",
    "## Obtaining Credentials\n",
    "\n",
    "- **Access Keys**: Access your storage account and navigate to the 'Access keys' section. Here, you will find the necessary credentials to access your Blob Storage programmatically.\n",
    "- **Shared Access Signature (SAS)**: Alternatively, you can create a SAS for more granular control over permissions and access duration.\n",
    "\n",
    "## Creating a Manifest JSON File\n",
    "\n",
    "In the root of your Azure container, create a manifest JSON file to keep track of your datasets. The file format is as follows:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"root_path\": \"https://[your-storage-account-name].blob.core.windows.net/[your-container-name]\",\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"image\": {\n",
    "                \"path\": [\"path/to/your/image_1\"],\n",
    "                \"id\": \"unique-uuid-1\"\n",
    "            },\n",
    "            \"label\": {\n",
    "                \"path\": [\"path/to/your/label_1\"],\n",
    "                \"id\": \"unique-uuid-2\"\n",
    "            }\n",
    "        },\n",
    "        // Additional data objects follow the same format\n",
    "    ]\n",
    "}\n",
    "````\n",
    "\n",
    "- Each dataset (training, testing, etc.) should have their own root directory\n",
    "- All the data should be under a root directory\n",
    "- The root directory should contain a `manifest.json` file\n",
    "- The `manifest.json` file should contain \"data\" field, which is a list of all the data entries\n",
    "- Each data entry should contain \"image\" and \"label\" fields\n",
    "- Each \"image\"/\"label\" field should contain \"path\" field, which is the list of relative path to the image/label files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "container_url = \"<remote object storage address>\"\n",
    "access_id = \"<user id>\"\n",
    "access_secret = \"<storage secret>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Remote Object to Create Datasets\n",
    "\n",
    "After you've completed the steps above, it's time to run the API to create your dataset.  Below you'll find an example request along with associated parameters and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"name\": \"MONAI_CLOUD\",\n",
    "    \"description\":\"Object storage dataset\",\n",
    "    \"type\": \"semantic_segmentation\",\n",
    "    \"format\": \"monai\",\n",
    "    \"location\": container_url,\n",
    "    \"client_id\": access_id,\n",
    "    \"client_secret\": access_secret,\n",
    "}\n",
    "\n",
    "endpoint = f\"{base_url}/dataset\"\n",
    "response = requests.post(endpoint, json=data, headers=headers)\n",
    "\n",
    "if response.status_code == 201:\n",
    "    res = response.json()\n",
    "    dataset_id = res[\"id\"]\n",
    "    print(\"Dataset creation succeeded with dataset ID： \", dataset_id)\n",
    "    print(\"---------------------------------\\n\")\n",
    "    print(json.dumps(res, indent=2))\n",
    "else:\n",
    "    print(response.json())\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom MONAI Bundle Creation\n",
    "\n",
    "1. **MONAI Bundle**: We're using the Spleen Segmentation bundle as an example. Choose the one fitting your application from the MONAI Model Zoo.\n",
    "2. **Dataset Setup**: All data is under one dataset ID for this demo. Adjust as per your data structure.\n",
    "3. **Pretrained Weights**: The Official MONAI bundles have pretrained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model creation succeeded with model ID：  e98ad72f-7f47-4ed0-844f-a242ecb414d8\n",
      "---------------------------------\n",
      "\n",
      "{\n",
      "  \"actions\": [\n",
      "    \"train\"\n",
      "  ],\n",
      "  \"additional_id_info\": null,\n",
      "  \"automl_add_hyperparameters\": \"\",\n",
      "  \"automl_algorithm\": null,\n",
      "  \"automl_enabled\": false,\n",
      "  \"automl_remove_hyperparameters\": \"\",\n",
      "  \"calibration_dataset\": null,\n",
      "  \"created_on\": \"2023-11-22T12:13:54.837278\",\n",
      "  \"dataset_type\": \"user_custom\",\n",
      "  \"description\": \"from MONAI model zoo\",\n",
      "  \"encryption_key\": \"tlt_encode\",\n",
      "  \"eval_dataset\": \"3a02d5dd-f940-4ddc-b593-e7d4aae07e23\",\n",
      "  \"id\": \"e98ad72f-7f47-4ed0-844f-a242ecb414d8\",\n",
      "  \"inference_dataset\": null,\n",
      "  \"jobs\": [],\n",
      "  \"last_modified\": \"2023-11-22T12:13:54.837296\",\n",
      "  \"logo\": \"https://www.nvidia.com\",\n",
      "  \"metric\": null,\n",
      "  \"model_params\": {},\n",
      "  \"name\": \"my_spleen_seg\",\n",
      "  \"network_arch\": \"monai_custom\",\n",
      "  \"ngc_path\": \"\",\n",
      "  \"ptm\": [\n",
      "    \"3f31f0e4-76f2-4fbb-a543-0189d06ea9c2\"\n",
      "  ],\n",
      "  \"public\": false,\n",
      "  \"read_only\": false,\n",
      "  \"realtime_infer\": false,\n",
      "  \"realtime_infer_request_timeout\": 60,\n",
      "  \"train_datasets\": [\n",
      "    \"3a02d5dd-f940-4ddc-b593-e7d4aae07e23\"\n",
      "  ],\n",
      "  \"type\": \"monai\",\n",
      "  \"version\": \"1.0.0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "bundle_url = \"https://github.com/Project-MONAI/model-zoo/releases/download/hosting_storage_v1/spleen_ct_segmentation_v0.5.3.zip\"\n",
    "\n",
    "data = {\n",
    "  \"name\": \"my_spleen_seg\",\n",
    "  \"description\": \"from MONAI model zoo\",\n",
    "  \"network_arch\": \"monai_custom\",  # must be using monai_custom\n",
    "  \"eval_dataset\": dataset_id,\n",
    "  \"train_datasets\": [ dataset_id ],\n",
    "  \"bundle_url\": bundle_url,\n",
    "}\n",
    "\n",
    "endpoint = f\"{base_url}/model\"\n",
    "response = requests.post(endpoint, json=data, headers=headers)\n",
    "if response.status_code == 201:\n",
    "    res = response.json()\n",
    "    model_id = res[\"id\"]\n",
    "    print(\"Model creation succeeded with model ID： \", model_id)\n",
    "    print(\"---------------------------------\\n\")\n",
    "    print(json.dumps(res, indent=2))\n",
    "else:\n",
    "    print(response.json())\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on DGX Cloud\n",
    "\n",
    "1. Users have the capability to submit jobs directly through our cloud API, enabling a streamlined and efficient process for initiating their projects.\n",
    "1. Additionally, users are empowered to modify the job submission payload, allowing the inclusion of additional parameters to tailor the execution according to specific requirements or preferences.\n",
    "1. The format of the payload aligns with the MONAI bundle configuration standards, ensuring a seamless integration and consistency in how data and parameters are structured and processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job submitted successfully with ce111b2c-c1d9-4fcd-85d6-c402df4484d7.\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "  \"epochs\": 10,\n",
    "}\n",
    "\n",
    "endpoint = f\"{base_url}/model/{model_id}/job/train\"\n",
    "response = requests.post(endpoint, json=data, headers=headers)\n",
    "\n",
    "if response.status_code == 201:\n",
    "    job_id = response.json()[0]\n",
    "    print(f\"Job submitted successfully with {job_id}.\")\n",
    "else:\n",
    "    print(response.json())\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring and Downloading\n",
    "\n",
    "Monitoring the status of your jobs is a crucial aspect of managing workflows effectively. In our system, the job monitoring feature provides a straightforward yet essential overview of your job's current state. Here's what you need to know:\n",
    "\n",
    "1. **Basic Status Overview**: The monitoring functionality in our system is designed to inform you whether your jobs are in a pending, running, or error state. This status update allows you to quickly assess the overall progress and detect any immediate issues that may require attention.\n",
    "\n",
    "2. **Detailed Logging Through Download API**: For a more comprehensive view and detailed logging of your jobs, our platform offers a Download API. This API enables you to access in-depth logs, model checkpoints, and data outputs, which are instrumental for troubleshooting, in-depth analysis, and gaining insights into the specifics of your job's execution. The Download API is particularly useful if your job encounters an error or if you need to understand the performance and behavior of your job in greater detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action: train\n",
      "created_on: 2023-11-22T12:14:19.577818\n",
      "id: ce111b2c-c1d9-4fcd-85d6-c402df4484d7\n",
      "last_modified: 2023-11-22T12:15:58.604297\n",
      "parent_id: None\n",
      "result:\n",
      "    categorical: []\n",
      "    cur_iter: None\n",
      "    detailed_status: {'date': '2023-11-22', 'message': 'MONAI job completed. Please download model artifacts to check.', 'status': 'SUCCESS', 'time': '2023-11-22T12:15:44.269236'}\n",
      "    epoch: 7\n",
      "    eta: None\n",
      "    graphical: []\n",
      "    key_metric: 0.05019168183207512\n",
      "    kpi: []\n",
      "    max_epoch: None\n",
      "    time_per_epoch: None\n",
      "    time_per_iter: None\n",
      "spec: {'cluster': 'local', 'epochs': 10, 'num_gpu': 1}\n",
      "status: Done\n"
     ]
    }
   ],
   "source": [
    "endpoint = f\"{base_url}/model/{model_id}/job/{job_id}\"\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    for k, v in response.json().items():\n",
    "        if k != \"result\":\n",
    "            print(f\"{k}: {v}\")\n",
    "        else:\n",
    "            print(\"result:\")\n",
    "            for k1, v1 in v.items():\n",
    "                print(f\"    {k1}: {v1}\")\n",
    "else:\n",
    "    print(response.json())\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downloading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/model/{model_id}/job/{job_id}/download\"\n",
    "response = requests.get(endpoint, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bundle training results are downloaded as ce111b2c-c1d9-4fcd-85d6-c402df4484d7.tar.gz\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    #save to file\n",
    "    attachment_data = response.content\n",
    "    with open(f\"{job_id}.tar.gz\", 'wb') as f:\n",
    "        f.write(attachment_data)\n",
    "    print(f\"Bundle training results are downloaded as {job_id}.tar.gz\")\n",
    "else:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "\"Congratulations on reaching this pivotal milestone! With your dataset created and model selected, you're now fully equipped to leverage the advanced features of the NVIDIA MONAI Cloud APIs for your medical imaging projects."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
