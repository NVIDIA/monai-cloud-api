{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide to Real-time Inference with NVIDIA Cloud APIs\n",
    "\n",
    "In this guide, we will guide you through the process of setting up a real-time inference system with MONAI cloud APIs. We will cover setting up the experiments, making on-the-fly predictions, and managing the outputs to ensure a seamless, efficient, and real-time decision-making pipeline.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NVIDIA/monai-cloud-api/blob/main/notebooks/Perform%20Real-time%20Inference.ipynb)\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- Introduction\n",
    "- Setup\n",
    "- Configuring Experiment to Enable the Real-Time Inference\n",
    "- Triggering Inference on a Specified Image\n",
    "- Stopping the Experiment from Real-Time Inference Mode\n",
    "- Cleaning up\n",
    "- Conclusion\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Transitioning to real-time inference can substantially elevate the responsiveness and applicability of AI models in healthcare. Analyzing and interpreting medical images as they are generated, and instantly providing insights, can be transformative, offering benefits such as improved patient outcomes and more efficient use of medical resources.\n",
    "\n",
    "### What You Can Expect to Learn\n",
    "\n",
    "This guide provides a detailed, step-by-step walkthrough for setting up a live session that facilitates real-time inference using the Vista 3D segmentation model. We'll cover how to configure your experiment for real-time processing, initiate inference on an image provided via URL, and conclude the session to free up GPU resources. The output from this real-time inference will be a series of multi-part files, specifically segmentation masks for the input image, which recognizes 132 classes using the Vista 3D model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import requests\" || pip install -q \"requests\"\n",
    "!python -c \"import requests_toolbelt\" || pip install -q \"requests_toolbelt\"\n",
    "!python -c \"import nrrd\" || pip install -q \"pynrrd\"\n",
    "!python -c \"import matplotlib\" || pip install -q \"matplotlib\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nrrd\n",
    "import requests\n",
    "from requests_toolbelt.multipart.decoder import MultipartDecoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# API Endpoint and Credentials\n",
    "host_url = \"https://api.monai.ngc.nvidia.com\"\n",
    "ngc_api_key = os.environ.get(\"MONAI_API_KEY\", \"<YOUR_API_KEY>\")  # we recommend using environment variables for API keys, but you can also hardcode them here\n",
    "inference_image_url = \"<inference image url>\"  # replace with your inference image url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Login into NGC and API Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exchange NGC_API_KEY for JWT\n",
    "api_url = f\"{host_url}/api/v1\"\n",
    "response = requests.post(f\"{api_url}/login\", json={\"ngc_api_key\": ngc_api_key})\n",
    "response.raise_for_status()\n",
    "assert \"user_id\" in response.json(), \"user_id is not in response.\"\n",
    "assert \"token\" in response.json(), \"token is not in response.\"\n",
    "user_id = response.json()[\"user_id\"]\n",
    "token = response.json()[\"token\"]\n",
    "\n",
    "# Construct the URL and Headers\n",
    "ngc_org = \"iasixjqzw1hj\"  # This is the default org for MONAI users. Please select the correct org if you are not using the default one.\n",
    "base_url = f\"{api_url}/orgs/{ngc_org}\"\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "print(\"API Calls will be forwarded to\", base_url)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring Experiment to Enable the Real-Time Inference\n",
    "\n",
    "#### Find the base experiment for VISTA-3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments:base\"\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "assert response.status_code == 200, f\"List base experiments failed, got {response.text}.\"\n",
    "res = response.json()\n",
    "\n",
    "# VISTA-3D\n",
    "vista3d_base_exps = [p for p in res[\"experiments\"] if p[\"network_arch\"] == \"monai_vista3d\"]\n",
    "assert len(vista3d_base_exps) > 0, \"No base experiment found for VISTA-3D.\"\n",
    "print(\"List of available base experiments for VISTA-3D:\")\n",
    "for exp in vista3d_base_exps:\n",
    "    print(f\"  {exp['id']}: {exp['name']} v{exp['version']}\")\n",
    "# Take the latest version\n",
    "base_experiment = sorted(vista3d_base_exps, key=lambda x: x[\"version\"])[-1]\n",
    "base_exp_vista = base_experiment[\"id\"]\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "print(f\"Base experiment ID for '{base_experiment['name']}' v{base_experiment['version']}: {base_exp_vista}\")\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "print(f\"Base Experiment ID for VISTA Experiment: {base_exp_vista}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new experiment and bootstrap it for real-time inference\n",
    "\n",
    "**Note:** We're going to use the `realtime_infer` parameter when creating our experiment as that will automatically load the experiment and make sure it's ready for real-time inference workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"name\": \"my_vista\",\n",
    "    \"description\": \"based on vista\",\n",
    "    \"network_arch\": \"monai_vista3d\",\n",
    "    \"base_experiment\": [base_exp_vista],\n",
    "    \"realtime_infer\": True,  # Auto loads MONAI bundle and enables real-time inference\n",
    "}\n",
    "\n",
    "endpoint = f\"{base_url}/experiments\"\n",
    "response = requests.post(endpoint, json=data, headers=headers)\n",
    "assert response.status_code == 201, f\"Create experiment failed, got {response.json()}.\"\n",
    "res = response.json()\n",
    "experiment_id = res[\"id\"]\n",
    "print(\"Experiment creation succeeded with experiment ID:\", experiment_id)\n",
    "print(\"---------------------------------\\n\")\n",
    "print(json.dumps(res, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triggering Inference on a Specified Image\n",
    "\n",
    "Initiate an inference process on a particular image within an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"action\": \"inference\",\n",
    "    \"specs\": {\n",
    "        \"image\": inference_image_url,\n",
    "        \"bundle_params\": {\n",
    "            \"label_prompt\": list(range(1, 133))  # inference all 132 classes\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "response = requests.post(endpoint, json=data, headers=headers)\n",
    "assert response.status_code == 201, f\"Run inference failed, got {response.json()}.\"\n",
    "print(\"Inference Successful.  Label is returned\")\n",
    "print(response.headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MultipartDecoder` is used to decode the response data. If it's not installed, you can use the following command to install it:\n",
    "\n",
    "```Bash\n",
    "pip install requests_toolbelt==1.0.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multipart_data = MultipartDecoder.from_response(response)\n",
    "for part in multipart_data.parts:\n",
    "    filename = part.headers[b\"Content-Disposition\"].decode().split(\";\")[1].split(\"=\")[1].strip('\"')\n",
    "\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(part.content)\n",
    "print(f\"Inference result downloaded to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vsiualize the Inference Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the nrrd file\n",
    "readdata, header = nrrd.read(filename)\n",
    "plt.imshow(readdata[:, :, readdata.shape[2] // 2], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopping the Experiment from Real-Time Inference Mode\n",
    "\n",
    "When the experiment is created with `realtime_infer` as `True`, it will reserve one GPU to process the inference requests.\n",
    "\n",
    "After we have finished the inference process, we would like to release the GPU resource for other tasks.\n",
    "\n",
    "To achieve this, we can switch the `realtime_infer` from `True` to `False`.\n",
    "\n",
    "Note: this step is irreversible, which means you can't set the `realtime_infer` from `False` to `True`. To bootstrap another inference, you will have to create another experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"realtime_infer\": False,\n",
    "}\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}\"\n",
    "response = requests.patch(endpoint, json=data, headers=headers)\n",
    "assert response.status_code == 200, f\"stop job failed, got {response.json()}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up\n",
    "Delete the experiment after jobs are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments/{experiment_id}\"\n",
    "response = requests.delete(endpoint, headers=headers)\n",
    "assert response.status_code == 200, f\"Delete experiment failed, got {response.json()}.\"\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This tutorial showcases a streamlined approach to real-time inference, emphasizing automation in image selection and processing within a NVIDIA MONAI Cloud API-driven system. This method ensures efficient operations, allowing users to focus on model refinement and analysis while the system efficiently manages image selection and inference tasks, demonstrating the transformative potential of integrating advanced AI in real-time decision-making workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "az-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
