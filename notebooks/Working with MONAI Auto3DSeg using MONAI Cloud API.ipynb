{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with MONAI Auto3DSeg using MONAI Cloud API\n",
    "This comprehensive guide is designed to help you navigate the process of training and testing with MONAI Auto3DSeg on the NVIDIA DGX Cloud, focusing on leveraging the powerful capabilities of DGX systems for medical imaging applications.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NVIDIA/monai-cloud-api/blob/main/notebooks//Working%20with%20MONAI%20Auto3DSeg%20using%20MONAI%20Cloud%20API.ipynb)\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- Introduction\n",
    "- Setup\n",
    "- Datasets Creation\n",
    "- Auto3DSeg Experiment Creation\n",
    "- Monitoring Job Status\n",
    "- AutoML Generated Model Inference\n",
    "- Cleanup\n",
    "- Conclusion\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Auto3DSeg is a MONAI native project, tailored to demonstrate optimal 3D segmentation workflows for various algorithms. It simplifies the process for non-experts, allowing them to train models on 3D CT or MRI data with just a few lines of code. For experts, it offers a compilation of best practices for segmentation training using MONAI components. This enables users to achieve and customize state-of-the-art baseline segmentation performances.\n",
    "\n",
    "A key focus of Auto3DSeg is on computational efficiency, aiming to minimize training and inference times while maximizing GPU compute utilization. Leveraging the MONAI Cloud API enhances this efficiency, streamlining data management and model training. Integrated with NVIDIA DGX Cloud, it provides scalable computational resources, ideal for handling large medical imaging datasets and complex training scenarios. This combination accelerates the development of advanced medical imaging solutions.\n",
    "\n",
    "### What You Can Expect to Learn\n",
    "\n",
    "This guide will lead you through the process of using MONAI Auto3DSeg to develop models on the NVIDIA DGX Cloud. By adhering to this tutorial, you'll be able to efficiently train models using your input datasets and evaluate the best segmentation models through Auto3DSeg’s streamlined workflows. All models created, along with the inference results, will be accessible on your remote cloud storage for detailed analysis.\n",
    "\n",
    "If you haven't already generated your key or if you're unsure about the process, follow our step-by-step guide for [Generating and Managing Your Credentials](./Generating%20and%20Managing%20Your%20Credentials.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import requests\" || pip install -q \"requests\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# API Endpoint and Credentials\n",
    "host_url = \"https://api.monai.ngc.nvidia.com\"\n",
    "ngc_api_key = os.environ.get(\"MONAI_API_KEY\", \"<YOUR_API_KEY>\")  # we recommend using environment variables for API keys, but you can also hardcode them here\n",
    "\n",
    "# The cloud storage type used in this notebook. Currently only support `aws` and `azure`.\n",
    "cloud_type = \"azure\" # cloud storage provider: aws or azure\n",
    "cloud_account = \"account_name\" # if cloud_type == \"aws\"  should be \"access_key\"\n",
    "cloud_secret = \"access_key\" # if cloud_type == \"aws\" should be \"secret_key\"\n",
    "\n",
    "# Cloud storage credentials. Needed for storing the data and results of the experiments.\n",
    "access_id = \"<user name for the remote storage object>\"                 # Please fill it with the actual Access ID\n",
    "access_secret = \"<secret for the remote storage object>\"                # Please fill it with the actual Access Secret\n",
    "\n",
    "# Data cloud storage URL, where training and inference datasets are stored.\n",
    "train_data_url = \"<container url for the training dataset>\"      # Training dataset container URL\n",
    "inference_data_url = \"<container url for the inference dataset>\" # Inference dataset container URL\n",
    "\n",
    "# Experiment cloud storage, where your jobs and experiments data will be stored.\n",
    "cs_bucket = \"<bucket/container name to push experiment job data to>\"  # Please fill it with the actual bucket name\n",
    "\n",
    "# MLFlow experiment tracking\n",
    "mlflow_tracking_uri = None                                       # [optional] MLFlow tracking URI \n",
    "mlflow_experiment_name = None                                    # [optional] MLFlow experiment name (defaults to Auto3DSeg)\n",
    "\n",
    "# Job configuration\n",
    "num_gpu = 1                                                      # Number of GPUs to use\n",
    "timeout = 3600                                                   # Time (in seconds) to wait for a job to be completed\n",
    "train_params = {}                                                # Training parameters. Optional because the Auto3DSeg can automatically tune the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Login into NGC and API setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exchange NGC_API_KEY for JWT\n",
    "api_url = f\"{host_url}/api/v1\"\n",
    "response = requests.post(f\"{api_url}/login\", data=json.dumps({\"ngc_api_key\": ngc_api_key}))\n",
    "assert response.status_code == 201, f\"Login failed, got status code: {response.status_code}.\"\n",
    "assert \"user_id\" in response.json(), \"user_id is not in response.\"\n",
    "assert \"token\" in response.json(), \"token is not in response.\"\n",
    "uid = response.json()[\"user_id\"]\n",
    "token = response.json()[\"token\"]\n",
    "\n",
    "# Construct the URL and Headers\n",
    "base_url = f\"{api_url}/orgs/iasixjqzw1hj\"  # This is the default org for MONAI users. Please select the correct org if you are not using the default one.\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Creation\n",
    "\n",
    "### **1. Remote Object as Data Sources**\n",
    "\n",
    "MONAI Cloud platform supports a range of other cloud storage solutions, including Azure Blob Storage, Google Cloud Storage (GCP) and Amazon S3, providing you with the flexibility to choose the service that best fits your project's needs. Below is an example of Azure:\n",
    "\n",
    "**Steps:**\n",
    "1. Creating a Storage Account and Container\n",
    "   - **Storage Account**: Start by creating a new storage account in your Azure portal. This account will host your blob storage containers.\n",
    "   - **Container Creation**: Within your storage account, create a new container. This container will hold your datasets.\n",
    "\n",
    "2. Container URL\n",
    "   - Once the container is created, you will be provided with a unique URL that can be used to access it. This URL will be essential for accessing your data.\n",
    "\n",
    "#### Obtaining Credentials\n",
    "\n",
    "- **Access Keys**: Access your storage account and navigate to the 'Access keys' section. Here, you will find the necessary credentials to access your Blob Storage programmatically.\n",
    "- **Shared Access Signature (SAS)**: Alternatively, you can create a SAS for more granular control over permissions and access duration.\n",
    "\n",
    "#### Creating a Manifest JSON File\n",
    "\n",
    "In the root of your Azure container, create a manifest JSON file to keep track of your datasets. The file format is as follows:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"root_path\": \"https://[your-storage-account-name].blob.core.windows.net/[your-container-name]\",\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"image\": {\n",
    "                \"path\": [\"path/to/your/image_1\"],\n",
    "                \"id\": \"unique-uuid-1\"\n",
    "            },\n",
    "            \"label\": {\n",
    "                \"path\": [\"path/to/your/label_1\"],\n",
    "                \"id\": \"unique-uuid-2\"\n",
    "            }\n",
    "        },\n",
    "        // Additional data objects follow the same format\n",
    "    ]\n",
    "}\n",
    "````\n",
    "\n",
    "- Each dataset (training, testing, etc.) should have their own root directory\n",
    "- All the data should be under a root directory\n",
    "- The root directory should contain a `manifest.json` file\n",
    "- The `manifest.json` file should contain \"data\" field, which is a list of all the data entries\n",
    "- Each data entry should contain \"image\" and \"label\" fields\n",
    "- Each \"image\"/\"label\" field should contain \"path\" field, which is the list of relative path to the image/label files\n",
    "\n",
    "\n",
    "After preparing your dataset, please modify the following variables in [Parameters](#Parameters):\n",
    "\n",
    "```python\n",
    "train_data_url = ...\n",
    "inference_data_url = ...\n",
    "access_id = ...\n",
    "access_secret = ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Creating the training datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_api = f\"{base_url}/datasets\"\n",
    "data = {\n",
    "    \"name\": \"train_sim_data_azure\",\n",
    "    \"description\": \"Simulated dataset for training Auto3DSeg on Azure\",\n",
    "    \"type\": \"semantic_segmentation\",\n",
    "    \"format\": \"monai\",\n",
    "    \"client_url\": train_data_url,\n",
    "    \"client_id\": access_id,\n",
    "    \"client_secret\": access_secret,\n",
    "}\n",
    "response = requests.post(dataset_api, json=data, headers=headers)\n",
    "assert response.status_code == 201, f\"Create dataset failed, got {response.json()}.\"\n",
    "res = response.json()\n",
    "train_dataset_id = res[\"id\"]\n",
    "print(\"Train dataset created with dataset ID：\", train_dataset_id)\n",
    "print(\"----------------------------------------------------------------------------\")\n",
    "print(json.dumps(res, indent=2))\n",
    "print(\"----------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Creating the inference datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_api = f\"{base_url}/datasets\"\n",
    "data = {\n",
    "    \"name\": \"test_sim_data_azure\",\n",
    "    \"description\": \"Simulated for evaluation of Auto3DSeg on Azure\",\n",
    "    \"type\": \"semantic_segmentation\",\n",
    "    \"format\": \"monai\",\n",
    "    \"client_url\": inference_data_url,\n",
    "    \"client_id\": access_id,\n",
    "    \"client_secret\": access_secret,\n",
    "}\n",
    "response = requests.post(dataset_api, json=data, headers=headers)\n",
    "assert response.status_code == 201, f\"Create dataset failed, got {response.json()}.\"\n",
    "res = response.json()\n",
    "infer_dataset_id = res[\"id\"]\n",
    "print(\"Inference dataset created with dataset ID:\", infer_dataset_id)\n",
    "print(\"-------------------------------------------------------------------------------\")\n",
    "print(json.dumps(res, indent=2))\n",
    "print(\"-------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto3DSeg Experiment Creation\n",
    "\n",
    "Users have the ability to initiate an experiment and execute the **auto3dseg** action to activate the Auto3DSeg pipeline. This process automatically sets up four distinct neural networks, undertaking multi-fold training to attain state-of-the-art performance in segmentation tasks. While the module is designed to be highly configurable to cater to various user needs, it maintains simplicity by requiring only minimal user input.\n",
    "\n",
    "Incorporating MONAI Cloud API into this workflow further enhances the user experience. The API facilitates seamless integration and management of data, models, and computational resources within a unified interface. This integration not only simplifies the process but also ensures efficient use of computational resources, particularly when running complex and resource-intensive tasks.\n",
    "\n",
    "**Minimal Inputs**\n",
    "\n",
    "Moreover, with the minimal input, users benefit from these advanced capabilities without needing to delve into complex configurations, making the Auto3DSeg pipeline accessible to a wide range of users, from beginners to experts in the field of medical imaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Find the base experiment for Auto3DSeg**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments:base\"\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "assert response.status_code == 200, f\"List experiment failed, got {response.text}.\"\n",
    "res = response.json()\n",
    "automl_base_exps = [p for p in res[\"experiments\"] if p[\"network_arch\"] == \"monai_automl\" and p[\"name\"] == \"MONAI Auto3dSeg\"]\n",
    "assert len(automl_base_exps) > 0, \"No base experiment found for Auto3DSeg Experiment\"\n",
    "print(f\"List of available base experiments for Auto3DSeg:\")\n",
    "for exp in automl_base_exps:\n",
    "    print(f\"  {exp['id']}: {exp['name']} v{exp['version']}\")\n",
    "# Take the latest version\n",
    "base_experiment = sorted(automl_base_exps, key=lambda x: x[\"version\"])[-1]\n",
    "base_experiment_id = base_experiment[\"id\"]\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "print(f\"Base experiment ID for '{base_experiment['name']}' v{base_experiment['version']}: {base_experiment_id}\")\n",
    "print(\"-----------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Create MONAI AutoML Experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_cloud_details = {\n",
    "    \"cloud_type\": cloud_type,\n",
    "    \"cloud_file_type\": \"folder\",  # If the file is tar.gz key in \"file\", else \"folder\"\n",
    "    \"cloud_specific_details\": {\n",
    "        \"cloud_bucket_name\": cs_bucket,  # Bucket link to save files\n",
    "        cloud_account: access_id,  # Access and Secret for Azure\n",
    "        cloud_secret: access_secret,  # Access and Secret for Azure\n",
    "    }\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"name\": \"automl_experiment\",\n",
    "    \"description\": \"MONAI AutoML Experiment for Segmentation\",\n",
    "    \"type\": \"medical\",\n",
    "    \"base_experiment\": [base_experiment_id],\n",
    "    \"network_arch\": \"monai_automl\",\n",
    "    \"train_datasets\": [train_dataset_id],\n",
    "    \"cloud_details\": experiment_cloud_details,\n",
    "}\n",
    "\n",
    "endpoint = f\"{base_url}/experiments\"\n",
    "response = requests.post(endpoint, json=data, headers=headers)\n",
    "assert response.status_code == 201, f\"Experiment creation failed, got {response.json()}.\"\n",
    "res = response.json()\n",
    "automl_experiment_id = res[\"id\"]\n",
    "print(\"Experiment creation succeeded with experiment ID:\", automl_experiment_id)\n",
    "print(\"--------------------------------------------------------------------------------------\")\n",
    "print(json.dumps(res, indent=2))\n",
    "print(\"--------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Run Auto3DSeg Action**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"action\": \"auto3dseg\",\n",
    "    \"specs\": {\n",
    "        \"num_gpu\": num_gpu,\n",
    "        \"output_experiment_name\": \"Auto3DSegGenModel\",\n",
    "        \"output_experiment_description\": \"AutoML generated segmentation experiment using MONAI Auto3DSeg\",\n",
    "        \"modality\": \"MRI\",\n",
    "        \"num_fold\": 1,\n",
    "        \"mlflow_tracking_uri\": mlflow_tracking_uri,\n",
    "        \"mlflow_experiment_name\": mlflow_experiment_name,\n",
    "        \"train_params\": train_params,\n",
    "    },\n",
    "}\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{automl_experiment_id}/jobs\"\n",
    "response = requests.post(endpoint, json=data, headers=headers)\n",
    "assert response.status_code == 201, f\"Create job failed, got {response.json()}.\"\n",
    "automl_job_id = response.json()\n",
    "print(\"Job creation succeeded with job ID:\", automl_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring Job Status\n",
    "\n",
    "**Metrics Tracking**\n",
    "If you have provided `mlflow_tracking_uri` in the payload data of the previous section, you can track the Auto3DSeg experiment by visiting the URL to the payload data.\n",
    "\n",
    "Monitoring the status of your jobs is a crucial aspect of managing workflows effectively. In our system, the job monitoring feature provides a straightforward yet essential overview of your job's current state. Here's what you need to know:\n",
    "\n",
    "**Basic Status Overview**: The monitoring functionality in our system is designed to inform you whether your jobs are in a pending, running, done, or error state. This status update allows you to quickly assess the overall progress and detect any immediate issues that may require attention.\n",
    "\n",
    "Status interpretation:\n",
    "- \"Pending\": MONAI cloud is looking for resources and preparing the datasets. This can take quite a while, and depends on the size of the dataset.\n",
    "- \"Running\": MONAI cloud has submitted the job to the DGX. \n",
    "- \"Done\": The training is complete\n",
    "- \"Error\": There is some error in the job. User probably wants to download the job as a `.tar.gz` archive and inspect the detailed log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_job(endpoint, headers, timeout=1800, interval=5, target_status=\"Done\"):\n",
    "    \"\"\"Helper function to wait for job to reach target status.\"\"\"\n",
    "    expected = [\"Pending\", \"Running\", \"Done\"]\n",
    "    assert target_status in expected, f\"Invalid target status: {target_status}\"\n",
    "    status_before_target = expected[:expected.index(target_status)]\n",
    "    start_time = time.time()\n",
    "    print(f\"Waiting for job to reach state {target_status} ...\")\n",
    "    status = None\n",
    "    while True:\n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        status_new = response.json()[\"status\"].title()\n",
    "        if time.time() - start_time > timeout:\n",
    "            print(f\"\\nJob timeout after {timeout} seconds with last status {status_new}.\")\n",
    "            break\n",
    "        elif status_new not in status_before_target:\n",
    "            assert status_new == target_status, f\"Job failed with status: {status_new}\"\n",
    "            print(f\"\\nJob reached target status: {status_new}\")\n",
    "            break\n",
    "        print(f\"\\n{status_new}\", end=\"\", flush=True) if status_new != status else print(\".\", end=\"\", flush=True)\n",
    "        status = status_new\n",
    "        time.sleep(interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments/{automl_experiment_id}/jobs/{automl_job_id}\"\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "\n",
    "assert response.status_code == 200, f\"Failed to get job status, got {response.json()}.\"\n",
    "for k, v in response.json().items():\n",
    "    if k != \"result\":\n",
    "        print(f\"{k}: {v}\")\n",
    "    else:\n",
    "        print(\"result:\")\n",
    "        for k1, v1 in v.items():\n",
    "            print(f\"    {k1}: {v1}\")\n",
    "\n",
    "print(\"------------------------------------------------------------------------\")\n",
    "wait_for_job(endpoint, headers, timeout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading job log\n",
    "\n",
    "The job log is available when the status of the job is \"RUNNING\", \"Error\" or \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments/{automl_experiment_id}/jobs/{automl_job_id}\"\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "assert response.status_code == 200, f\"Failed to get job status, got {response.json()}.\"\n",
    "status = response.json()[\"status\"].title()\n",
    "if status in [\"Running\", \"Done\", \"Error\"]:\n",
    "    endpoint = f\"{base_url}/experiments/{automl_experiment_id}/jobs/{automl_job_id}/logs\"\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    assert response.status_code == 200, f\"Failed to get job logs, got {response.text}.\"\n",
    "    print(response.text)\n",
    "else:\n",
    "    print(f\"Job status: {status}, logs are not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the job results (checkpoint, scripts, logs, etc.)\n",
    "\n",
    "You'll find the results in the cloud storage bucket you specified when creating the experiment. The results will include the model checkpoints, scripts, logs, and other relevant data.\n",
    "\n",
    "The path to the results will be in the following format:\n",
    "\n",
    "```python\n",
    "f\"{bucket_name}/shared/orgs/{ngc_org}/users/{user_id}/jobs/{job_id}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Generated Model Inference\n",
    "\n",
    "Users can easily deploy models trained via the Auto3DSeg pipeline for inference on their test datasets. This process involves selecting an AutoML-optimized model, tailored for high accuracy and efficiency in medical imaging tasks. The trained model is then applied to the test dataset, allowing users to evaluate its performance in real-world scenarios. This seamless integration from training to inference exemplifies the practical utility of Auto3DSeg in streamlining complex medical imaging analyses.\n",
    "\n",
    "Note: Auto3DSeg will generate only one model/experiment at each job run but if you have run multiple jobs (with different or same parameters), you will see multiple generated experiments in the next step. To better distinguish them, we recommend to assign different names to `\"output_experiment_name\"` in parameters when running new jobs inthe previous step and search for those specific names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **1. List the experiments and select the last generated Auto3DSeg experiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments\"\n",
    "params = {\"user_only\": True, \"network_arch\": \"monai_automl_generated\"}\n",
    "# you can use the assigned \"output_experiment_name\" in the previous steps to filter the experiments\n",
    "# params = {\"user_only\": True, \"network_arch\": \"monai_automl_generated\", \"name\": \"Auto3DSegGenModel\"}\n",
    "response = requests.get(endpoint, params=params, headers=headers)\n",
    "assert response.status_code == 200, f\"List experiment failed, got {response.json()}.\"\n",
    "experiments = response.json()[\"experiments\"]\n",
    "assert len(experiments) > 0, \"No experiments found!\"\n",
    "selected = \"x\"\n",
    "for m in experiments:\n",
    "    print(f'- {selected} {m[\"name\"]:25} : {m[\"id\"]} ({m[\"created_on\"]})')\n",
    "    selected = \" \"\n",
    "experiment_id = experiments[0][\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. [Optional] List more information about the selected experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments/{experiment_id}\"\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "\n",
    "assert response.status_code == 200, f\"Failed to get experiment info, got {response.json()}.\"\n",
    "for k, v in response.json().items():\n",
    "    if k != \"result\":\n",
    "        print(f\"{k}: {v}\")\n",
    "    else:\n",
    "        print(\"result:\")\n",
    "        for k1, v1 in v.items():\n",
    "            print(f\"    {k1}: {v1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Run Inference**\n",
    "\n",
    "With the model and the `inference_dataset` prepared, users can prepare the payload data and submit an inference request as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"action\": \"batchinfer\",\n",
    "    \"specs\": {\n",
    "        \"inference_dataset\": infer_dataset_id,\n",
    "    },\n",
    "}\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "response = requests.post(endpoint, json=data, headers=headers)\n",
    "\n",
    "assert response.status_code == 201, f\"Create job failed, got {response.json()}.\"\n",
    "infer_job_id = response.json()\n",
    "print(\"Job creation succeeded with job ID:\", infer_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Check on the Inference Job**\n",
    "\n",
    "After the job is submitted, users can continue to use the APIs to check the status of the inference job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{infer_job_id}\"\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "\n",
    "assert response.status_code == 200, f\"Failed to get job status, got {response.json()}.\"\n",
    "for k, v in response.json().items():\n",
    "    if k != \"result\":\n",
    "        print(f\"{k}: {v}\")\n",
    "    else:\n",
    "        print(\"result:\")\n",
    "        for k1, v1 in v.items():\n",
    "            print(f\"    {k1}: {v1}\")\n",
    "\n",
    "wait_for_job(endpoint, headers, timeout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Download the Log of the Inference Job**\n",
    "\n",
    "Finally, when the jobs are completed, users should be able to check the inference results on the cloud storage. They can also download the job log to examine the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{infer_job_id}\"\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "assert response.status_code == 200, f\"Failed to get job status, got {response.json()}.\"\n",
    "status = response.json()[\"status\"].title()\n",
    "if status in [\"Running\", \"Done\", \"Error\"]:\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{infer_job_id}/logs\"\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    assert response.status_code == 200, f\"Failed to get job logs, got {response.text}.\"\n",
    "    print(response.text)\n",
    "else:\n",
    "    print(f\"Job status: {status}, logs are not available.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the experiment and datasets after jobs are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cancel automl job and inference job if not Done. This step is required before cleaning data\n",
    "endpoint = f\"{base_url}/experiments/{automl_experiment_id}/jobs/{automl_job_id}\"\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "if response.json()[\"status\"] != \"Done\":\n",
    "    endpoint = f\"{base_url}/experiments/{automl_experiment_id}/jobs/{automl_job_id}:cancel\"\n",
    "    response = requests.post(endpoint, headers=headers)\n",
    "    assert response.status_code == 200, f\"Cancel job {automl_job_id} failed, got {response.json()}.\"\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{infer_job_id}\"\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "if response.json()[\"status\"] != \"Done\":\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{infer_job_id}:cancel\"\n",
    "    response = requests.post(endpoint, headers=headers)\n",
    "    assert response.status_code == 200, f\"Cancel job {infer_job_id} failed, got {response.json()}.\"\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments/{automl_experiment_id}\"\n",
    "response = requests.delete(endpoint, headers=headers)\n",
    "assert response.status_code == 200, f\"Delete automl experiment failed, got {response.json()}.\"\n",
    "print(response)\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}\"\n",
    "response = requests.delete(endpoint, headers=headers)\n",
    "assert response.status_code == 200, f\"Delete inference experiment failed, got {response.json()}.\"\n",
    "print(response)\n",
    "\n",
    "endpoint = f\"{base_url}/datasets/{train_dataset_id}\"\n",
    "response = requests.delete(endpoint, headers=headers)\n",
    "assert response.status_code == 200, f\"Delete train dataset failed, got {response.json()}.\"\n",
    "print(response)\n",
    "\n",
    "endpoint = f\"{base_url}/datasets/{infer_dataset_id}\"\n",
    "response = requests.delete(endpoint, headers=headers)\n",
    "assert response.status_code == 200, f\"Delete inference dataset failed, got {response.json()}.\"\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In conclusion, the combination of Auto3DSeg with the MONAI Cloud API and NVIDIA DGX Cloud marks a significant stride in medical imaging technology. It simplifies the 3D segmentation process and harnesses the potential of AutoML, making advanced medical imaging analysis more accessible and efficient for both beginners and experts. This integration, facilitating a smooth progression from model training to inference, showcases the practical and powerful capabilities of this approach in enhancing medical imaging workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
