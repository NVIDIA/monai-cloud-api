{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical Image Generation with MAISI\n",
    "\n",
    "This guide is designed to help you navigate the process of generating medical image on the NVIDIA DGX Cloud, focusing on leveraging the powerful capabilities of DGX systems for medical imaging applications.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/NVIDIA/monai-cloud-api/blob/main/notebooks/Medical%20Image%20Generation%20with%20MAISI.ipynb)\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- Introduction\n",
    "- Setup\n",
    "- MAISI Experiment Creation\n",
    "- Generating Medical Image\n",
    "- Download the Job Log\n",
    "- Download the Generated Medical Images\n",
    "- Visualize the Generated Medical Images\n",
    "- Conclusion\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Synthetic medical image generation using generative AI has emerged as a powerful technique in the field of medical imaging. It allows researchers, healthcare professionals, and developers to generate realistic and high-fidelity medical images, such as CT scans, without the need for extensive data collection or patient involvement.\n",
    "\n",
    "CT (Computed Tomography) scans are widely used in medical diagnosis, treatment planning, and research. They provide detailed cross-sectional images of the body, allowing healthcare professionals to visualize internal structures and identify abnormalities.\n",
    "\n",
    "Traditionally, obtaining a large dataset of CT scans for research or training purposes can be challenging due to privacy concerns, limited access to patient data, and the time-consuming process of acquiring scans. Synthetic medical image generation addresses these challenges by leveraging generative AI models to generate synthetic CT scans that closely resemble real patient scans.\n",
    "\n",
    "Generative AI models, such as generative adversarial networks (GANs) and variational autoencoders (VAEs), learn the underlying patterns and structures of real CT scans from a limited dataset. They then generate new CT scans that exhibit similar characteristics, including anatomical structures, tissue densities, and noise patterns.\n",
    "\n",
    "### What You Can Expect to Learn\n",
    "\n",
    "In the end of this guide, you will be able to generate synthetic CT scans using the MAISI model on the NVIDIA DGX Cloud. These synthetic CT scans can be used for a variety of applications, including medical imaging research, algorithm development, education, and training.\n",
    "\n",
    "![image.png](./end2end_pic/maisi.png)\n",
    "\n",
    "By generating synthetic CT scans, researchers and developers can:\n",
    "\n",
    "- Augment limited datasets: Synthetic CT scans can be used to augment small or imbalanced datasets, improving the performance and generalization of machine learning models.\n",
    "- Privacy-preserving research: Synthetic CT scans eliminate the need for accessing sensitive patient data, ensuring privacy compliance while enabling collaborative research.\n",
    "- Simulation and testing: Synthetic CT scans can be used for simulating different clinical scenarios, testing algorithms, and evaluating the performance of medical imaging systems.\n",
    "- Education and training: Synthetic CT scans provide a valuable resource for medical education and training, allowing students and healthcare professionals to practice interpreting and analyzing scans.\n",
    "\n",
    "To get started, make sure you have generated your credentials by following the step-by-step guide on [Generating and Managing Your Credentials](./Generating%20and%20Managing%20Your%20Credentials.ipynb). These credentials will be required for accessing the NVIDIA DGX Cloud and running the MAISI experiments.\n",
    "\n",
    "In this guide, we will explore the process of synthetic medical image generation using MAISI, specifically focusing on CT scans. We will cover the setup and the generation of synthetic CT scans using NVIDIA DGX Cloud.\n",
    "\n",
    "Let's embark on this exciting journey of synthetic medical image generation and unlock new possibilities in medical imaging research and applications!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import requests\" || pip install -q \"requests\"\n",
    "!python -c \"import nibabel\" || pip install -q \"nibabel\"\n",
    "!python -c \"import numpy\" || pip install -q \"numpy\"\n",
    "!python -c \"import matplotlib\" || pip install -q \"matplotlib\"\n",
    "!python -c \"import libcloud\" || pip install -q \"apache-libcloud\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import requests\n",
    "from libcloud.storage.providers import get_driver\n",
    "from libcloud.storage.types import Provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Required Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# API Endpoint and Credentials\n",
    "host_url = \"https://api.monai.ngc.nvidia.com\"\n",
    "ngc_api_key = os.environ.get(\"MONAI_API_KEY\", \"<YOUR_API_KEY>\")  # we recommend using environment variables for API keys, but you can also hardcode them here\n",
    "\n",
    "# The cloud storage type used in this notebook. Currently only support `aws` and `azure`.\n",
    "cloud_type = \"azure\"  # cloud storage provider: aws or azure\n",
    "cloud_account = \"account_name\"  # if cloud_type == \"aws\"  should be \"access_key\"\n",
    "cloud_secret = \"access_key\"  # if cloud_type == \"aws\" should be \"secret_key\"\n",
    "\n",
    "# Cloud storage credentials. Needed for storing the data and results of the experiments.\n",
    "access_id = \"<user name for the remote storage object>\"  # Please fill it with the actual Access ID\n",
    "access_secret = \"<secret for the remote storage object>\"  # Please fill it with the actual Access Secret\n",
    "cs_bucket = \"<bucket/container name to push the experiment job data to>\"  # Please fill it with the actual bucket name\n",
    "\n",
    "# Job configuration\n",
    "timeout = 3600  # Time (in seconds) to wait for a job to be completed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Login into NGC and API Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exchange NGC_API_KEY for JWT\n",
    "api_url = f\"{host_url}/api/v1\"\n",
    "response = requests.post(f\"{api_url}/login\", json={\"ngc_api_key\": ngc_api_key})\n",
    "response.raise_for_status()\n",
    "assert \"user_id\" in response.json(), \"user_id is not in response.\"\n",
    "assert \"token\" in response.json(), \"token is not in response.\"\n",
    "user_id = response.json()[\"user_id\"]\n",
    "token = response.json()[\"token\"]\n",
    "\n",
    "# Construct the URL and Headers\n",
    "ngc_org = \"iasixjqzw1hj\"  # This is the default org for MONAI users. Please select the correct org if you are not using the default one.\n",
    "base_url = f\"{api_url}/orgs/{ngc_org}\"\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "print(\"API Calls will be forwarded to\", base_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAISI Experiment Creation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the base experiment for MAISI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments:base\"\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "assert response.status_code == 200, f\"List base experiments failed, got {response.text}.\"\n",
    "res = response.json()\n",
    "\n",
    "gen_ai_base_exps = [p for p in res[\"experiments\"] if p[\"network_arch\"] == \"monai_maisi\"]\n",
    "assert len(gen_ai_base_exps) > 0, \"No base experiment found for MAISI\"\n",
    "print(\"List of available base experiments for MAISI:\")\n",
    "for exp in gen_ai_base_exps:\n",
    "    print(f\"  {exp['id']}: {exp['name']} v{exp['version']}\")\n",
    "# Take the latest version\n",
    "base_experiment = sorted(gen_ai_base_exps, key=lambda x: x[\"version\"])[-1]\n",
    "version = base_experiment[\"version\"]\n",
    "base_exp_maisi = base_experiment[\"id\"]\n",
    "print(\"-----------------------------------------------------------------------------------------\")\n",
    "print(f\"Base experiment ID for '{base_experiment['name']}' v{base_experiment['version']}: {base_exp_maisi}\")\n",
    "print(\"-----------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create MAISI Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_cloud_details = {\n",
    "    \"cloud_type\": cloud_type,\n",
    "    \"cloud_file_type\": \"folder\",  # If the file is tar.gz key in \"file\", else \"folder\"\n",
    "    \"cloud_specific_details\": {\n",
    "        \"cloud_bucket_name\": cs_bucket,  # Bucket link to upload results to\n",
    "        cloud_account: access_id,  # Access and Secret for Azure\n",
    "        cloud_secret: access_secret,  # Access and Secret for Azure\n",
    "    }\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"name\": \"maisi_experiment\",\n",
    "    \"description\": \"MONAI MAISI experiment\",\n",
    "    \"type\": \"medical\",\n",
    "    \"base_experiment\": [base_exp_maisi],\n",
    "    \"network_arch\": \"monai_maisi\",\n",
    "    \"cloud_details\": experiment_cloud_details,\n",
    "}\n",
    "\n",
    "endpoint = f\"{base_url}/experiments\"\n",
    "response = requests.post(endpoint, json=data, headers=headers)\n",
    "assert response.status_code == 201, f\"Experiment creation failed, got {response.json()}.\"\n",
    "res = response.json()\n",
    "experiment_id = res[\"id\"]\n",
    "print(\"Experiment creation succeeded with experiment ID:\", experiment_id)\n",
    "print(\"--------------------------------------------------------------------------------------\")\n",
    "print(json.dumps(res, indent=2))\n",
    "print(\"--------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Medical Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supported_body_region = [\"head\", \"chest\", \"thorax\", \"abdomen\", \"pelvis\", \"lower\"]\n",
    "supported_organs = [\"liver\", \"kidney\", \"spleen\", \"pancreas\", \"right kidney\", \"aorta\", \"inferior vena cava\", \"right adrenal gland\", \"left adrenal gland\", \"gallbladder\", \"esophagus\", \"stomach\", \"duodenum\", \"left kidney\", \"bladder\", \"prostate or uterus\", \"portal vein and splenic vein\", \"rectum\", \"small bowel\", \"lung\", \"bone\", \"brain\", \"lung tumor\", \"pancreatic tumor\", \"hepatic vessel\", \"hepatic tumor\", \"colon cancer primaries\", \"left lung upper lobe\", \"left lung lower lobe\", \"right lung upper lobe\", \"right lung middle lobe\", \"right lung lower lobe\", \"vertebrae L5\", \"vertebrae L4\", \"vertebrae L3\", \"vertebrae L2\", \"vertebrae L1\", \"vertebrae T12\", \"vertebrae T11\", \"vertebrae T10\", \"vertebrae T9\", \"vertebrae T8\", \"vertebrae T7\", \"vertebrae T6\", \"vertebrae T5\", \"vertebrae T4\", \"vertebrae T3\", \"vertebrae T2\", \"vertebrae T1\", \"vertebrae C7\", \"vertebrae C6\", \"vertebrae C5\", \"vertebrae C4\", \"vertebrae C3\", \"vertebrae C2\", \"vertebrae C1\", \"trachea\", \"left iliac artery\", \"right iliac artery\", \"left iliac vena\", \"right iliac vena\", \"colon\", \"left rib 1\", \"left rib 2\", \"left rib 3\", \"left rib 4\", \"left rib 5\", \"left rib 6\", \"left rib 7\", \"left rib 8\", \"left rib 9\", \"left rib 10\", \"left rib 11\", \"left rib 12\", \"right rib 1\", \"right rib 2\", \"right rib 3\", \"right rib 4\", \"right rib 5\", \"right rib 6\", \"right rib 7\", \"right rib 8\", \"right rib 9\", \"right rib 10\", \"right rib 11\", \"right rib 12\", \"left humerus\", \"right humerus\", \"left scapula\", \"right scapula\", \"left clavicula\", \"right clavicula\", \"left femur\", \"right femur\", \"left hip\", \"right hip\", \"sacrum\", \"left gluteus maximus\", \"right gluteus maximus\", \"left gluteus medius\", \"right gluteus medius\", \"left gluteus minimus\", \"right gluteus minimus\", \"left autochthon\", \"right autochthon\", \"left iliopsoas\", \"right iliopsoas\", \"left atrial appendage\", \"brachiocephalic trunk\", \"left brachiocephalic vein\", \"right brachiocephalic vein\", \"left common carotid artery\", \"right common carotid artery\", \"costal cartilages\", \"heart\", \"left kidney cyst\", \"right kidney cyst\", \"prostate\", \"pulmonary vein\", \"skull\", \"spinal cord\", \"sternum\", \"left subclavian artery\", \"right subclavian artery\", \"superior vena cava\", \"thyroid gland\", \"vertebrae S1\", \"bone lesion\", \"kidney mass\", \"liver tumor\", \"vertebrae L6\", \"airway\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"action\": \"generate\",\n",
    "    \"specs\": {\n",
    "        \"num_output_samples\": 1,                    # Number of output samples\n",
    "        \"body_region\": [\"chest\"],                   # Body region (please refer to the list above for the supported body regions)\n",
    "        \"organ_list\": [\"liver\"],                    # Organs (please refer to the list above for the supported organs)\n",
    "    },\n",
    "}\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "response = requests.post(endpoint, json=data, headers=headers)\n",
    "\n",
    "assert response.status_code == 201, f\"Create job failed, got {response.json()}.\"\n",
    "job_id = response.json()\n",
    "print(f\"Job creation succeeded with job ID: {job_id}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring Job Status\n",
    "\n",
    "Please note that the job will take about 45 minutes to complete, plus the additional time in job queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_job(endpoint, headers, timeout=3600, interval=5, target_status=\"Done\"):\n",
    "    \"\"\"Helper function to wait for job to reach target status.\"\"\"\n",
    "    expected = [\"Pending\", \"Running\", \"Done\"]\n",
    "    assert target_status in expected, f\"Invalid target status: {target_status}\"\n",
    "    status_before_target = expected[:expected.index(target_status)]\n",
    "    start_time = time.time()\n",
    "    print(f\"Waiting for job to reach state {target_status} ...\")\n",
    "    status = None\n",
    "    while True:\n",
    "        response = requests.get(endpoint, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        status_new = response.json()[\"status\"].title()\n",
    "        if time.time() - start_time > timeout:\n",
    "            print(f\"\\nJob timeout after {timeout} seconds with last status {status_new}.\")\n",
    "            break\n",
    "        elif status_new not in status_before_target:\n",
    "            assert status_new == target_status, f\"Job failed with status: {status_new}\"\n",
    "            print(f\"\\nJob reached target status: {status_new}\")\n",
    "            break\n",
    "        print(f\"\\n{status_new}\", end=\"\", flush=True) if status_new != status else print(\".\", end=\"\", flush=True)\n",
    "        status = status_new\n",
    "        time.sleep(interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "\n",
    "assert response.status_code == 200, f\"Failed to get job status, got {response.json()}.\"\n",
    "for k, v in response.json().items():\n",
    "    if k != \"result\":\n",
    "        print(f\"{k}: {v}\")\n",
    "    else:\n",
    "        print(\"result:\")\n",
    "        for k1, v1 in v.items():\n",
    "            print(f\"    {k1}: {v1}\")\n",
    "\n",
    "wait_for_job(endpoint, headers, timeout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Job Log\n",
    "\n",
    "Finally, when the jobs are completed, users should be able to check the inference results on the cloud storage. They can also download the job log to examine the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "assert response.status_code == 200, f\"Failed to get job status, got {response.json()}.\"\n",
    "status = response.json()[\"status\"].title()\n",
    "if status in [\"Running\", \"Done\", \"Error\"]:\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}/logs\"\n",
    "    response = requests.get(endpoint, headers=headers)\n",
    "    assert response.status_code == 200, f\"Failed to get job logs, got {response.text}.\"\n",
    "    print(response.text)\n",
    "else:\n",
    "    print(f\"Job status: {status}, logs are not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the Generated Medical Images\n",
    "\n",
    "Download the generated medical images from the cloud storage to your local machine for further analysis, visualization, and integration into medical imaging applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = f\"shared/orgs/{ngc_org}/users/{user_id}/jobs/{job_id}/maisi_v{version}/output\"\n",
    "\n",
    "if cloud_type == \"aws\":\n",
    "    cs_driver = get_driver(Provider.S3)\n",
    "elif cloud_type == \"azure\":\n",
    "    cs_driver = get_driver(Provider.AZURE_BLOBS)\n",
    "\n",
    "driver = cs_driver(access_id, access_secret, region=\"us-west-1\")\n",
    "container = driver.get_container(container_name=cs_bucket)\n",
    "\n",
    "file_objects = driver.list_container_objects(container=container, ex_prefix=folder)\n",
    "for obj in file_objects:\n",
    "    local_destination = obj.name\n",
    "    print(\"Downloading object: %s\" % obj.name)\n",
    "    obj.download(os.path.basename(obj.name), overwrite_existing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Generated Medical Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the downloaded file\n",
    "image_file = sorted([f for f in os.listdir() if f.endswith(\"_image.nii.gz\")])[0]\n",
    "label_file = sorted([f for f in os.listdir() if f.endswith(\"_label.nii.gz\")])[0]\n",
    "\n",
    "# Plotting\n",
    "slice_indices = [192, 208, 224, 240, 256, 272, 288, 304, 320]  # 3x3 grid of slices for each image/label.\n",
    "fig, axes = plt.subplots(nrows=3, ncols=6, figsize=(10, 5))\n",
    "\n",
    "for idx, slice_index in enumerate(slice_indices):\n",
    "    for i, file in enumerate([image_file, label_file]):\n",
    "        # Load the image and label files\n",
    "        data = nib.load(file).get_fdata()\n",
    "        slice = np.fliplr(np.rot90(data[:, slice_index, :], 1))\n",
    "        axes[idx // 3, idx % 3 + i * 3].imshow(slice, cmap='gray' if i == 0 else 'viridis')\n",
    "        axes[idx // 3, idx % 3 + i * 3].axis('off')  # Hide the axes ticks\n",
    "    idx += 1\n",
    "axes[0, 1].set_title(\"Generated Image Slices\")\n",
    "axes[0, 4].set_title(\"Generated Label Slices\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete the experiment after all jobs are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}\"\n",
    "response = requests.get(endpoint, headers=headers)\n",
    "# If the job is not done, need to cancel it first\n",
    "if response.json()[\"status\"] != \"Done\":\n",
    "    endpoint = f\"{base_url}/experiments/{experiment_id}/jobs/{job_id}:cancel\"\n",
    "    response = requests.post(endpoint, headers=headers)\n",
    "    assert response.status_code == 200, f\"Cancel job failed, got {response.json()}.\"\n",
    "    print(response)\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}\"\n",
    "response = requests.delete(endpoint, headers=headers)\n",
    "assert response.status_code == 200, f\"Delete experiment failed, got {response.json()}.\"\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project, we explored the potential of MAISI in the field of medical imaging. We implemented a generative model that can create new, synthetic medical images. This has vast implications for medical research and training, as it allows for the generation of large datasets without the need for patient involvement or the associated privacy concerns.\n",
    "\n",
    "However, it's important to note that while the results are promising, the technology is not without its limitations and ethical considerations. The quality of the generated images is highly dependent on the quality and diversity of the training data. Additionally, care must be taken to ensure that the synthetic images do not misrepresent or oversimplify complex medical conditions.\n",
    "\n",
    "In conclusion, MAISI holds great promise in the field of medical imaging, offering a powerful tool for research, training, and potentially even diagnosis and treatment planning. However, as with any powerful tool, it must be used responsibly and ethically.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
