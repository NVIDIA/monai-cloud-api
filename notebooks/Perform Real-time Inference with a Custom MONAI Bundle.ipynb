{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guide to do Real-time Inference on a Custom MONAI Bundle with NVIDIA Cloud APIs\n",
    "\n",
    "In this guide, we will guide you through the process of setting up a real-time inference system on a custom MONAI bundle with MONAI cloud APIs. We'll cover setting up the environment, performing on-the-fly predictions, and managing the output to ensure a seamless, efficient, and real-time decision-making pipeline.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "- Introduction\n",
    "- Setup\n",
    "- Dataset Creation\n",
    "- Custom MONAI Bundle Creation\n",
    "- Configuring Experiment to enable the real-time inference\n",
    "- Prepare the image ID for the inference request\n",
    "- Triggering Inference on a Specified Image\n",
    "- Stopping the experiment from Realtime Inference mode\n",
    "- Cleaning up\n",
    "- Conclusion\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Transitioning to real-time inference can substantially elevate the responsiveness and applicability of AI models in healthcare. Analyzing and interpreting medical images as they are generated, and instantly providing insights, can be transformative, offering benefits such as improved patient outcomes and more efficient use of medical resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Setup'></a>\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# API Endpoint and Credentials\n",
    "host_url = \"https://api.monai.ngc.nvidia.com\"\n",
    "ngc_api_key = os.environ.get('MONAI_API_KEY')\n",
    "# Object storage info\n",
    "access_id = \"<user id>\"\n",
    "access_secret = \"<storage secret>\"\n",
    "container_url = \"<remote object storage address>\"\n",
    "inference_image_id = \"<inference image id>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exchange NGC_API_KEY for JWT\n",
    "data = json.dumps({\"ngc_api_key\": ngc_api_key})\n",
    "response = requests.post(f\"{host_url}/api/v1/login\", data=data)\n",
    "print(response.status_code)\n",
    "assert response.status_code == 201, f\"Login failed, got status code: {response.status_code}.\"\n",
    "assert \"user_id\" in response.json().keys(), \"user_id is not in response.\"\n",
    "user_id = response.json()[\"user_id\"]\n",
    "print(\"User ID\",user_id)\n",
    "assert \"token\" in response.json().keys(), \"token is not in response.\"\n",
    "token = response.json()[\"token\"]\n",
    "print(\"JWT\",token)\n",
    "\n",
    "# Construct the URL and Headers\n",
    "base_url = f\"{host_url}/api/v1/orgs/iasixjqzw1hj\"\n",
    "print(\"API Calls will be forwarded to\",base_url)\n",
    "\n",
    "headers = {\"Authorization\": f\"Bearer {token}\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation\n",
    "\n",
    "### **1. Remote Object as Data Sources**\n",
    "\n",
    "MONAI Cloud platform supports a range of other cloud storage solutions, including Azure Blob Storage, Google Cloud Storage (GCP) and Amazon S3, providing you with the flexibility to choose the service that best fits your project's needs. Below is an example of Azure:\n",
    "\n",
    "**Steps:**\n",
    "1. Creating a Storage Account and Container\n",
    "   - **Storage Account**: Start by creating a new storage account in your Azure portal. This account will host your blob storage containers.\n",
    "   - **Container Creation**: Within your storage account, create a new container. This container will hold your datasets.\n",
    "\n",
    "2. Container URL\n",
    "   - Once the container is created, you will be provided with a unique URL that can be used to access it. This URL will be essential for accessing your data.\n",
    "\n",
    "## Obtaining Credentials\n",
    "\n",
    "- **Access Keys**: Access your storage account and navigate to the 'Access keys' section. Here, you will find the necessary credentials to access your Blob Storage programmatically.\n",
    "- **Shared Access Signature (SAS)**: Alternatively, you can create a SAS for more granular control over permissions and access duration.\n",
    "\n",
    "## Creating a Manifest JSON File\n",
    "\n",
    "In the root of your Azure container, create a manifest JSON file to keep track of your datasets. The file format is as follows:\n",
    "\n",
    "For a segmentation task:\n",
    "```json\n",
    "{\n",
    "    \"root_path\": \"https://[your-storage-account-name].blob.core.windows.net/[your-container-name]/[subfolder-path]\",\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"image\": {\n",
    "                \"path\": [\"path/to/your/image_1\"],\n",
    "                \"id\": \"unique-uuid-1\"\n",
    "            },\n",
    "            \"label\": {\n",
    "                \"path\": [\"path/to/your/label_1\"],\n",
    "                \"id\": \"unique-uuid-2\"\n",
    "            }\n",
    "        },\n",
    "        // Additional data objects follow the same format\n",
    "    ]\n",
    "}\n",
    "````\n",
    "\n",
    "For a non-segmentation task:\n",
    "```json\n",
    "{\n",
    "    \"root_path\": \"https://[your-storage-account-name].blob.core.windows.net/[your-container-name]\",\n",
    "    \"label_key\": [\"bbox\", \"label\"],\n",
    "    \"data\": [\n",
    "        {\n",
    "            \"image\": {\n",
    "                \"path\": [\"path/to/your/image_1\"],\n",
    "                \"id\": \"unique-uuid-1\"\n",
    "            },\n",
    "            \"bbox\": ...,\n",
    "            \"label\": ...\n",
    "        }\n",
    "        // Additional data objects should follow the same format\n",
    "    ]\n",
    "}\n",
    "```\n",
    "\n",
    "- Each dataset (training, testing, etc.) should have their own root directory\n",
    "- All the data should be under a root directory\n",
    "- The root directory should contain a `manifest.json` file\n",
    "- The `manifest.json` file should contain \"data\" field, which is a list of all the data entries\n",
    "- Each data entry should contain \"image\" and \"label\" fields\n",
    "- Each \"image\"/\"label\" field should contain \"path\" field, which is the list of relative path to the image/label files\n",
    "- Please provide the \"id\" field of the \"image\"/\"label\", if there is not one please provide a random uuid generated by `uuid` package\n",
    "- The `label_key` is optional, with a default of `[\"label\"]`\n",
    "\n",
    "After preparing your dataset, please modify the following variables in [Setup](#Setup):\n",
    "\n",
    "```python\n",
    "access_id = ...\n",
    "access_secret = ...\n",
    "container_url = ...\n",
    "inference_image_id = ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Remote Object to Create Datasets\n",
    "\n",
    "After you've completed the steps above, it's time to run the API to create your dataset.  Below you'll find an example request along with associated parameters and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"name\": \"MONAI_CLOUD\",\n",
    "    \"description\":\"Object storage dataset\",\n",
    "    \"type\": \"semantic_segmentation\",\n",
    "    \"format\": \"monai\",\n",
    "    \"client_url\": container_url,\n",
    "    \"client_id\": access_id,\n",
    "    \"client_secret\": access_secret,\n",
    "}\n",
    "\n",
    "endpoint = f\"{base_url}/datasets\"\n",
    "response = requests.post(endpoint, json=data, headers=headers)\n",
    "\n",
    "assert response.status_code == 201, f\"Create dataset failed, got {response.json()}.\"\n",
    "\n",
    "res = response.json()\n",
    "dataset_id = res[\"id\"]\n",
    "print(\"Dataset creation succeeded with dataset ID: \", dataset_id)\n",
    "print(\"---------------------------------\\n\")\n",
    "print(json.dumps(res, indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom MONAI Bundle Creation\n",
    "\n",
    "1. **MONAI Bundle**: We're using the Endoscopic Inbody Classification MONAI bundle from the MONAI Model Zoo as an example. Users can build their own MONAI bundles fitting their applications.\n",
    "2. **Dataset Setup**: All data is under one dataset ID for this demo. Adjust as per your data structure.\n",
    "3. **Pretrained Weights**: The Official MONAI bundles have pretrained weights.\n",
    "\n",
    "Here are some notes about the payload used to create the experiment:\n",
    "\n",
    "- name: A user-defined name for the training experiment, here named \"my_inbody_clf\".\n",
    "- description: A brief description of the experiment. Optional\n",
    "- network_arch: Specifies the architecture of the network. The value \"monai_custom\" indicates that a custom network architecture is being used. The user must provide the `bundle_url` with such custom architecture.\n",
    "- bundle_url: Indicating the specific location of the MONAI bundle to be used in this training experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring Experiment to enable the real-time inference\n",
    "\n",
    "**Note:** We're going to use the `realtime_infer` parameter when creating our experiment as that will automatically load the experiment and make sure it's ready for real-time inference workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_url = \"https://api.ngc.nvidia.com/v2/models/nvidia/monaihosting/endoscopic_inbody_classification/versions/0.4.6/files/endoscopic_inbody_classification_v0.4.6.zip\"\n",
    "    \n",
    "data = {\n",
    "  \"name\": \"my_inbody_clf\",\n",
    "  \"description\": \"from MONAI model zoo\",\n",
    "  \"network_arch\": \"monai_custom\",\n",
    "  \"train_datasets\": [ dataset_id ],\n",
    "  \"eval_dataset\": dataset_id,\n",
    "  \"realtime_infer\": True,\n",
    "  \"bundle_url\": bundle_url,\n",
    "  \"model_params\": {\"override\": {\"output_filename\": \"realtime_inference_predictions.csv\"}}\n",
    "}\n",
    "\n",
    "endpoint = f\"{base_url}/experiments\"\n",
    "response = requests.post(endpoint, json=data, headers=headers)\n",
    "assert response.status_code == 201, f\"Create experiment failed, got {response.json()}.\"\n",
    "res = response.json()\n",
    "experiment_id = res[\"id\"]\n",
    "model_network = res[\"network_arch\"]\n",
    "print(\"Experiment creation succeeded with experiment ID:\", experiment_id)\n",
    "print(\"---------------------------------\\n\")\n",
    "print(json.dumps(res, indent=2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the image ID for the inference request\n",
    "\n",
    "Getting the ID of the image to process:\n",
    "- The code sends a request to the \"cacheimage\" action. Users need to specify an image_id manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an inference image id with nextimage api\n",
    "data = {\n",
    "    \"action\": \"cacheimage\",\n",
    "    \"specs\": {\"image\": inference_image_id}\n",
    "}\n",
    "endpoint = f\"{base_url}/datasets/{dataset_id}/jobs\"\n",
    "response = requests.post(endpoint, json=data, headers=headers)\n",
    "\n",
    "assert response.status_code == 201, f\"cache image failed, got {response.json()}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triggering Inference on a Specified Image\n",
    "\n",
    "Initiate an inference process on a particular image within an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"action\": \"inference\",\n",
    "    \"specs\": {\n",
    "        \"image\": inference_image_id\n",
    "    }\n",
    "}\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}/jobs\"\n",
    "response = requests.post(endpoint, json=data, headers=headers)\n",
    "assert response.status_code == 201, f\"Run inference failed, got {response.json()}.\"\n",
    "print(\"Inference Successful.  Label is returned\")\n",
    "print(response.headers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`MultipartDecoder` is used to decode the response data. If it's not installed, you can use the following command to install it:\n",
    "\n",
    "```Bash\n",
    "pip install requests_toolbelt==1.0.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests_toolbelt.multipart.decoder import MultipartDecoder\n",
    "\n",
    "multipart_data = MultipartDecoder.from_response(response)\n",
    "for part in multipart_data.parts:\n",
    "    filename = part.headers[b\"Content-Disposition\"].decode().split(\";\")[1].split(\"=\")[1].strip('\"')\n",
    "\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(part.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopping the experiment from Realtime Inference mode\n",
    "\n",
    "When the experiment is created with `realtime_infer` as `True`, it will reserve one GPU to process the inference requests.\n",
    "\n",
    "After we have finished the inference process, we would like to release the GPU resource for other tasks.\n",
    "\n",
    "To achieve this, we can switch the `realtime_infer` from `True` to `False`.\n",
    "\n",
    "Note: this step is irreversible, which means you can't set the `realtime_infer` from `False` to `True`. To bootstrap another inference, you will have to create another experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"realtime_infer\": False,\n",
    "}\n",
    "\n",
    "endpoint = f\"{base_url}/experiments/{experiment_id}\"\n",
    "response = requests.patch(endpoint, json=data, headers=headers)\n",
    "assert response.status_code == 200, f\"stop job failed, got {response.json()}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning up\n",
    "Delete the experiment and dataset after jobs are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = f\"{base_url}/experiments/{experiment_id}\"\n",
    "response = requests.delete(endpoint, headers=headers)\n",
    "assert response.status_code == 200, f\"Delete experiment failed, got {response.json()}.\"\n",
    "print(response)\n",
    "\n",
    "endpoint = f\"{base_url}/datasets/{dataset_id}\"\n",
    "response = requests.delete(endpoint, headers=headers)\n",
    "assert response.status_code == 200, f\"Delete dataset failed, got {response.json()}.\"\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The code snippets showcase a streamlined approach to do real-time inference on a custom MONAI bundle, and processing within a NVIDIA MONAI Cloud API-driven system. This method ensures seamless, efficient operations, allowing users to focus on model refinement and analysis while the system efficiently manages image selection and inference tasks, demonstrating the transformative potential of integrating advanced AI in real-time decision-making workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
